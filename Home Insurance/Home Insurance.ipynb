{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\matplotlib\\__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run external scripts\n",
    "%run scripts/helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load train and test files\n",
    "train = pd.read_csv('./data/train.csv', parse_dates=['Original_Quote_Date'], index_col='QuoteNumber')\n",
    "test = pd.read_csv('./data/test.csv', parse_dates=['Original_Quote_Date'], index_col='QuoteNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260753, 298)\n",
      "(173836, 297)\n"
     ]
    }
   ],
   "source": [
    "# size of training and test set\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform column names to lowercase\n",
    "\n",
    "train.columns = train.columns.map(lambda x: x.lower())\n",
    "test.columns = test.columns.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "C:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:259: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  return aux[:-1][aux[1:] == aux[:-1]]\n"
     ]
    }
   ],
   "source": [
    "# encode categorical features\n",
    "train, test = encode_labels(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the original_quote_date into year_original_quote_date,\n",
    "# month_original_quote_date, quarter_original_quote_date and weekday\n",
    "# and drop the original_quote_date feature\n",
    "\n",
    "train['year_original_quote_date'] = train.original_quote_date.dt.year\n",
    "train['month_original_quote_date'] = train.original_quote_date.dt.month\n",
    "train['quarter_original_quote_date'] = train.original_quote_date.dt.quarter\n",
    "train['weekday_original_quote_date'] = train.original_quote_date.dt.weekday\n",
    "\n",
    "test['year_original_quote_date'] = test.original_quote_date.dt.year\n",
    "test['month_original_quote_date'] = test.original_quote_date.dt.month\n",
    "test['quarter_original_quote_date'] = test.original_quote_date.dt.quarter\n",
    "test['weekday_original_quote_date'] = test.original_quote_date.dt.weekday\n",
    "\n",
    "train = train.drop('original_quote_date', axis=1)\n",
    "test = test.drop('original_quote_date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop columns with constant values\n",
    "\n",
    "train = train.drop('propertyfield6', axis=1)\n",
    "train = train.drop('geographicfield10a', axis=1)\n",
    "\n",
    "test = test.drop('propertyfield6', axis=1)\n",
    "test = test.drop('geographicfield10a', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing value with -1 to indicate that this is a missing value\n",
    "\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take stratified sample from the dataset ( only 30% of the total examples )\n",
    "train_sample = get_stratified_sample(train, train.quoteconversion_flag, percentage=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# separate features and target variable\n",
    "train_features = train_sample[train_sample.columns.drop('quoteconversion_flag')]\n",
    "target = train_sample.quoteconversion_flag\n",
    "\n",
    "test_features = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130376, 298)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the samples\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide into training and test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91263, 298) (39113, 298)\n"
     ]
    }
   ],
   "source": [
    "# shape of X_train and X_test\n",
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stratified K Fold settings\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score\n",
    "skf = StratifiedKFold(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a extreme gradient boosting classifier\n",
    "params = dict([('objective', 'binary:logistic'),\n",
    "               ('eval_metric', 'auc'),\n",
    "               ('eta', 0.01),\n",
    "               ('subsample', 0.8),\n",
    "               ('colsample_bytree', 0.8),\n",
    "               ('min_child_weight', 5),\n",
    "               ('max_depth', 10),\n",
    "               ('nthread', 8)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training and test exmples DMatrix\n",
    "xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_list = [(xgb_test,'eval'), (xgb_train,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 10 rounds.\n",
      "[0]\teval-auc:0.950423\ttrain-auc:0.952989\n",
      "[1]\teval-auc:0.954765\ttrain-auc:0.957377\n",
      "[2]\teval-auc:0.955375\ttrain-auc:0.958048\n",
      "[3]\teval-auc:0.956649\ttrain-auc:0.959802\n",
      "[4]\teval-auc:0.956667\ttrain-auc:0.960457\n",
      "[5]\teval-auc:0.955936\ttrain-auc:0.960297\n",
      "[6]\teval-auc:0.956831\ttrain-auc:0.960903\n",
      "[7]\teval-auc:0.956328\ttrain-auc:0.960732\n",
      "[8]\teval-auc:0.957217\ttrain-auc:0.961249\n",
      "[9]\teval-auc:0.956446\ttrain-auc:0.961005\n",
      "[10]\teval-auc:0.956933\ttrain-auc:0.961219\n",
      "[11]\teval-auc:0.957305\ttrain-auc:0.961413\n",
      "[12]\teval-auc:0.957504\ttrain-auc:0.961568\n",
      "[13]\teval-auc:0.957661\ttrain-auc:0.961662\n",
      "[14]\teval-auc:0.957643\ttrain-auc:0.961905\n",
      "[15]\teval-auc:0.957733\ttrain-auc:0.961958\n",
      "[16]\teval-auc:0.957783\ttrain-auc:0.962017\n",
      "[17]\teval-auc:0.957901\ttrain-auc:0.962034\n",
      "[18]\teval-auc:0.957958\ttrain-auc:0.962060\n",
      "[19]\teval-auc:0.958015\ttrain-auc:0.962022\n",
      "[20]\teval-auc:0.958102\ttrain-auc:0.962063\n",
      "[21]\teval-auc:0.958152\ttrain-auc:0.962099\n",
      "[22]\teval-auc:0.958106\ttrain-auc:0.962135\n",
      "[23]\teval-auc:0.958214\ttrain-auc:0.962305\n",
      "[24]\teval-auc:0.958201\ttrain-auc:0.962264\n",
      "[25]\teval-auc:0.958204\ttrain-auc:0.962228\n",
      "[26]\teval-auc:0.958271\ttrain-auc:0.962331\n",
      "[27]\teval-auc:0.958279\ttrain-auc:0.962411\n",
      "[28]\teval-auc:0.958329\ttrain-auc:0.962424\n",
      "[29]\teval-auc:0.958416\ttrain-auc:0.962491\n",
      "[30]\teval-auc:0.958454\ttrain-auc:0.962475\n",
      "[31]\teval-auc:0.958419\ttrain-auc:0.962452\n",
      "[32]\teval-auc:0.958439\ttrain-auc:0.962461\n",
      "[33]\teval-auc:0.958474\ttrain-auc:0.962453\n",
      "[34]\teval-auc:0.958536\ttrain-auc:0.962484\n",
      "[35]\teval-auc:0.958515\ttrain-auc:0.962484\n",
      "[36]\teval-auc:0.958583\ttrain-auc:0.962495\n",
      "[37]\teval-auc:0.958598\ttrain-auc:0.962501\n",
      "[38]\teval-auc:0.958622\ttrain-auc:0.962524\n",
      "[39]\teval-auc:0.958658\ttrain-auc:0.962554\n",
      "[40]\teval-auc:0.958679\ttrain-auc:0.962560\n",
      "[41]\teval-auc:0.958712\ttrain-auc:0.962606\n",
      "[42]\teval-auc:0.958737\ttrain-auc:0.962645\n",
      "[43]\teval-auc:0.958735\ttrain-auc:0.962653\n",
      "[44]\teval-auc:0.958729\ttrain-auc:0.962668\n",
      "[45]\teval-auc:0.958750\ttrain-auc:0.962767\n",
      "[46]\teval-auc:0.958747\ttrain-auc:0.962763\n",
      "[47]\teval-auc:0.958780\ttrain-auc:0.962804\n",
      "[48]\teval-auc:0.958842\ttrain-auc:0.962947\n",
      "[49]\teval-auc:0.958862\ttrain-auc:0.962981\n",
      "[50]\teval-auc:0.958972\ttrain-auc:0.963109\n",
      "[51]\teval-auc:0.958963\ttrain-auc:0.963122\n",
      "[52]\teval-auc:0.958957\ttrain-auc:0.963127\n",
      "[53]\teval-auc:0.958971\ttrain-auc:0.963155\n",
      "[54]\teval-auc:0.958974\ttrain-auc:0.963179\n",
      "[55]\teval-auc:0.959013\ttrain-auc:0.963265\n",
      "[56]\teval-auc:0.959036\ttrain-auc:0.963357\n",
      "[57]\teval-auc:0.959063\ttrain-auc:0.963390\n",
      "[58]\teval-auc:0.959081\ttrain-auc:0.963408\n",
      "[59]\teval-auc:0.959137\ttrain-auc:0.963424\n",
      "[60]\teval-auc:0.959130\ttrain-auc:0.963411\n",
      "[61]\teval-auc:0.959132\ttrain-auc:0.963419\n",
      "[62]\teval-auc:0.959147\ttrain-auc:0.963432\n",
      "[63]\teval-auc:0.959164\ttrain-auc:0.963519\n",
      "[64]\teval-auc:0.959185\ttrain-auc:0.963539\n",
      "[65]\teval-auc:0.959196\ttrain-auc:0.963548\n",
      "[66]\teval-auc:0.959222\ttrain-auc:0.963634\n",
      "[67]\teval-auc:0.959257\ttrain-auc:0.963730\n",
      "[68]\teval-auc:0.959238\ttrain-auc:0.963754\n",
      "[69]\teval-auc:0.959244\ttrain-auc:0.963752\n",
      "[70]\teval-auc:0.959259\ttrain-auc:0.963838\n",
      "[71]\teval-auc:0.959295\ttrain-auc:0.963860\n",
      "[72]\teval-auc:0.959335\ttrain-auc:0.963899\n",
      "[73]\teval-auc:0.959356\ttrain-auc:0.963910\n",
      "[74]\teval-auc:0.959383\ttrain-auc:0.963957\n",
      "[75]\teval-auc:0.959478\ttrain-auc:0.964029\n",
      "[76]\teval-auc:0.959494\ttrain-auc:0.964043\n",
      "[77]\teval-auc:0.959513\ttrain-auc:0.964064\n",
      "[78]\teval-auc:0.959516\ttrain-auc:0.964074\n",
      "[79]\teval-auc:0.959544\ttrain-auc:0.964109\n",
      "[80]\teval-auc:0.959556\ttrain-auc:0.964193\n",
      "[81]\teval-auc:0.959544\ttrain-auc:0.964204\n",
      "[82]\teval-auc:0.959620\ttrain-auc:0.964267\n",
      "[83]\teval-auc:0.959653\ttrain-auc:0.964347\n",
      "[84]\teval-auc:0.959677\ttrain-auc:0.964372\n",
      "[85]\teval-auc:0.959684\ttrain-auc:0.964390\n",
      "[86]\teval-auc:0.959693\ttrain-auc:0.964415\n",
      "[87]\teval-auc:0.959718\ttrain-auc:0.964435\n",
      "[88]\teval-auc:0.959721\ttrain-auc:0.964455\n",
      "[89]\teval-auc:0.959719\ttrain-auc:0.964483\n",
      "[90]\teval-auc:0.959723\ttrain-auc:0.964487\n",
      "[91]\teval-auc:0.959749\ttrain-auc:0.964554\n",
      "[92]\teval-auc:0.959756\ttrain-auc:0.964557\n",
      "[93]\teval-auc:0.959784\ttrain-auc:0.964600\n",
      "[94]\teval-auc:0.959792\ttrain-auc:0.964640\n",
      "[95]\teval-auc:0.959808\ttrain-auc:0.964646\n",
      "[96]\teval-auc:0.959816\ttrain-auc:0.964670\n",
      "[97]\teval-auc:0.959808\ttrain-auc:0.964673\n",
      "[98]\teval-auc:0.959841\ttrain-auc:0.964718\n",
      "[99]\teval-auc:0.959911\ttrain-auc:0.964793\n",
      "[100]\teval-auc:0.959923\ttrain-auc:0.964802\n",
      "[101]\teval-auc:0.959961\ttrain-auc:0.964891\n",
      "[102]\teval-auc:0.959981\ttrain-auc:0.964931\n",
      "[103]\teval-auc:0.960029\ttrain-auc:0.965032\n",
      "[104]\teval-auc:0.960031\ttrain-auc:0.965031\n",
      "[105]\teval-auc:0.960033\ttrain-auc:0.965074\n",
      "[106]\teval-auc:0.960056\ttrain-auc:0.965143\n",
      "[107]\teval-auc:0.960059\ttrain-auc:0.965209\n",
      "[108]\teval-auc:0.960065\ttrain-auc:0.965219\n",
      "[109]\teval-auc:0.960088\ttrain-auc:0.965291\n",
      "[110]\teval-auc:0.960095\ttrain-auc:0.965307\n",
      "[111]\teval-auc:0.960124\ttrain-auc:0.965363\n",
      "[112]\teval-auc:0.960113\ttrain-auc:0.965397\n",
      "[113]\teval-auc:0.960117\ttrain-auc:0.965405\n",
      "[114]\teval-auc:0.960135\ttrain-auc:0.965450\n",
      "[115]\teval-auc:0.960150\ttrain-auc:0.965505\n",
      "[116]\teval-auc:0.960181\ttrain-auc:0.965545\n",
      "[117]\teval-auc:0.960201\ttrain-auc:0.965575\n",
      "[118]\teval-auc:0.960202\ttrain-auc:0.965618\n",
      "[119]\teval-auc:0.960205\ttrain-auc:0.965645\n",
      "[120]\teval-auc:0.960224\ttrain-auc:0.965731\n",
      "[121]\teval-auc:0.960221\ttrain-auc:0.965747\n",
      "[122]\teval-auc:0.960221\ttrain-auc:0.965768\n",
      "[123]\teval-auc:0.960238\ttrain-auc:0.965823\n",
      "[124]\teval-auc:0.960256\ttrain-auc:0.965846\n",
      "[125]\teval-auc:0.960275\ttrain-auc:0.965894\n",
      "[126]\teval-auc:0.960276\ttrain-auc:0.965913\n",
      "[127]\teval-auc:0.960301\ttrain-auc:0.965999\n",
      "[128]\teval-auc:0.960319\ttrain-auc:0.966034\n",
      "[129]\teval-auc:0.960338\ttrain-auc:0.966061\n",
      "[130]\teval-auc:0.960353\ttrain-auc:0.966098\n",
      "[131]\teval-auc:0.960360\ttrain-auc:0.966132\n",
      "[132]\teval-auc:0.960371\ttrain-auc:0.966161\n",
      "[133]\teval-auc:0.960395\ttrain-auc:0.966220\n",
      "[134]\teval-auc:0.960384\ttrain-auc:0.966240\n",
      "[135]\teval-auc:0.960388\ttrain-auc:0.966294\n",
      "[136]\teval-auc:0.960403\ttrain-auc:0.966300\n",
      "[137]\teval-auc:0.960415\ttrain-auc:0.966314\n",
      "[138]\teval-auc:0.960422\ttrain-auc:0.966322\n",
      "[139]\teval-auc:0.960445\ttrain-auc:0.966378\n",
      "[140]\teval-auc:0.960459\ttrain-auc:0.966392\n",
      "[141]\teval-auc:0.960481\ttrain-auc:0.966427\n",
      "[142]\teval-auc:0.960493\ttrain-auc:0.966429\n",
      "[143]\teval-auc:0.960496\ttrain-auc:0.966441\n",
      "[144]\teval-auc:0.960505\ttrain-auc:0.966461\n",
      "[145]\teval-auc:0.960511\ttrain-auc:0.966477\n",
      "[146]\teval-auc:0.960510\ttrain-auc:0.966490\n",
      "[147]\teval-auc:0.960539\ttrain-auc:0.966547\n",
      "[148]\teval-auc:0.960586\ttrain-auc:0.966587\n",
      "[149]\teval-auc:0.960607\ttrain-auc:0.966639\n",
      "[150]\teval-auc:0.960622\ttrain-auc:0.966684\n",
      "[151]\teval-auc:0.960625\ttrain-auc:0.966717\n",
      "[152]\teval-auc:0.960622\ttrain-auc:0.966732\n",
      "[153]\teval-auc:0.960660\ttrain-auc:0.966800\n",
      "[154]\teval-auc:0.960667\ttrain-auc:0.966820\n",
      "[155]\teval-auc:0.960669\ttrain-auc:0.966827\n",
      "[156]\teval-auc:0.960687\ttrain-auc:0.966874\n",
      "[157]\teval-auc:0.960695\ttrain-auc:0.966913\n",
      "[158]\teval-auc:0.960713\ttrain-auc:0.966954\n",
      "[159]\teval-auc:0.960710\ttrain-auc:0.966965\n",
      "[160]\teval-auc:0.960740\ttrain-auc:0.967021\n",
      "[161]\teval-auc:0.960762\ttrain-auc:0.967056\n",
      "[162]\teval-auc:0.960777\ttrain-auc:0.967071\n",
      "[163]\teval-auc:0.960783\ttrain-auc:0.967088\n",
      "[164]\teval-auc:0.960793\ttrain-auc:0.967107\n",
      "[165]\teval-auc:0.960818\ttrain-auc:0.967172\n",
      "[166]\teval-auc:0.960842\ttrain-auc:0.967204\n",
      "[167]\teval-auc:0.960872\ttrain-auc:0.967237\n",
      "[168]\teval-auc:0.960878\ttrain-auc:0.967296\n",
      "[169]\teval-auc:0.960879\ttrain-auc:0.967322\n",
      "[170]\teval-auc:0.960890\ttrain-auc:0.967327\n",
      "[171]\teval-auc:0.960905\ttrain-auc:0.967348\n",
      "[172]\teval-auc:0.960907\ttrain-auc:0.967372\n",
      "[173]\teval-auc:0.960929\ttrain-auc:0.967439\n",
      "[174]\teval-auc:0.960943\ttrain-auc:0.967481\n",
      "[175]\teval-auc:0.960940\ttrain-auc:0.967491\n",
      "[176]\teval-auc:0.960965\ttrain-auc:0.967550\n",
      "[177]\teval-auc:0.960975\ttrain-auc:0.967615\n",
      "[178]\teval-auc:0.960978\ttrain-auc:0.967640\n",
      "[179]\teval-auc:0.960994\ttrain-auc:0.967658\n",
      "[180]\teval-auc:0.961004\ttrain-auc:0.967709\n",
      "[181]\teval-auc:0.961015\ttrain-auc:0.967754\n",
      "[182]\teval-auc:0.961033\ttrain-auc:0.967811\n",
      "[183]\teval-auc:0.961031\ttrain-auc:0.967820\n",
      "[184]\teval-auc:0.961037\ttrain-auc:0.967840\n",
      "[185]\teval-auc:0.961039\ttrain-auc:0.967849\n",
      "[186]\teval-auc:0.961051\ttrain-auc:0.967868\n",
      "[187]\teval-auc:0.961051\ttrain-auc:0.967884\n",
      "[188]\teval-auc:0.961054\ttrain-auc:0.967900\n",
      "[189]\teval-auc:0.961065\ttrain-auc:0.967918\n",
      "[190]\teval-auc:0.961090\ttrain-auc:0.967957\n",
      "[191]\teval-auc:0.961099\ttrain-auc:0.968007\n",
      "[192]\teval-auc:0.961103\ttrain-auc:0.968028\n",
      "[193]\teval-auc:0.961133\ttrain-auc:0.968048\n",
      "[194]\teval-auc:0.961153\ttrain-auc:0.968103\n",
      "[195]\teval-auc:0.961154\ttrain-auc:0.968118\n",
      "[196]\teval-auc:0.961163\ttrain-auc:0.968172\n",
      "[197]\teval-auc:0.961190\ttrain-auc:0.968202\n",
      "[198]\teval-auc:0.961217\ttrain-auc:0.968247\n",
      "[199]\teval-auc:0.961218\ttrain-auc:0.968318\n",
      "[200]\teval-auc:0.961228\ttrain-auc:0.968343\n",
      "[201]\teval-auc:0.961226\ttrain-auc:0.968350\n",
      "[202]\teval-auc:0.961223\ttrain-auc:0.968372\n",
      "[203]\teval-auc:0.961242\ttrain-auc:0.968403\n",
      "[204]\teval-auc:0.961260\ttrain-auc:0.968442\n",
      "[205]\teval-auc:0.961292\ttrain-auc:0.968473\n",
      "[206]\teval-auc:0.961293\ttrain-auc:0.968488\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-bf16574ce09c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# xgboost model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, early_stopping_rounds, evals_result, verbose_eval)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mbst_eval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\xgboost\\core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid training matrix: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# xgboost model\n",
    "model = xgb.train(params, xgb_train, num_boost_round=1000, early_stopping_rounds=10, evals=eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on the heldout test set 0.955666 \n"
     ]
    }
   ],
   "source": [
    "# score on heldout test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict on test examples\n",
    "y_test_preds = gs.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print 'Score on the heldout test set %f ' %(roc_auc_score(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bytree=0.8, gamma=0,\n",
       "       learning_rate=0.08, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', seed=0, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on the training set\n",
    "xgb_clf.fit(X_train, y_train, eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions on the test set\n",
    "y_test_preds = xgb_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on the test set 0.963220 \n"
     ]
    }
   ],
   "source": [
    "# test your AUC score on the test set\n",
    "print 'AUC score on the test set %f ' %(roc_auc_score(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validation curves\n",
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "param_range = [10, 50, 75, 100]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    RandomForestClassifier(), train_features, target, param_name=\"n_estimators\", param_range=param_range,\n",
    "    cv=3, scoring=\"roc_auc\", n_jobs=1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlim(10, 100)\n",
    "plt.ylim(0.0, 1.1)\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bytree=0.8, gamma=0,\n",
       "       learning_rate=0.03, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=5, missing=None, n_estimators=150, nthread=-1,\n",
       "       objective='binary:logistic', seed=0, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on full dataset\n",
    "xgb_clf.fit(train_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = xgb_clf.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['QuoteConversion_Flag'] = predictions\n",
    "submission.to_csv('./submissions/tenth_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
