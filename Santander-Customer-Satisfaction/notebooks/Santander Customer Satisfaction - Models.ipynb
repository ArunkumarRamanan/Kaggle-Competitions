{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "# np.random.seed(1294)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col='ID')\n",
    "test = pd.read_csv('../data/test.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get features with zero standard deviation\n",
    "def get_constant_features(df):\n",
    "    columns = df.columns\n",
    "    return [col for col in columns if df[col].std() == 0.0]\n",
    "\n",
    "constant_features = get_constant_features(train)\n",
    "\n",
    "# get features which are identical to other features\n",
    "def get_identical_features(df):\n",
    "    columns = df.columns\n",
    "    identical_feat = []\n",
    "    \n",
    "    for i in range(len(columns)):\n",
    "        for j in range(i+1, len(columns)):\n",
    "            if (df[columns[i]] == df[columns[j]]).all():\n",
    "                identical_feat.append(columns[i])\n",
    "    \n",
    "    return identical_feat\n",
    "\n",
    "identical_feat = get_identical_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features_to_remove(constant_features, identical_features):\n",
    "    features_to_remove = []\n",
    "    \n",
    "    for feat in constant_features:\n",
    "        features_to_remove.append(feat)\n",
    "    \n",
    "    for feat in identical_features:\n",
    "        features_to_remove.append(feat)\n",
    "    \n",
    "    return features_to_remove\n",
    "\n",
    "remove_features = get_features_to_remove(constant_features, identical_feat)\n",
    "remove_features.append('delta_imp_aport_var13_1y3')\n",
    "remove_features.append('delta_num_aport_var13_1y3')\n",
    "remove_features.append('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_features = train.columns.drop(remove_features)\n",
    "X = train[reduced_features]\n",
    "y = train.TARGET\n",
    "\n",
    "test = test[reduced_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (38010, 304) and X_test shape (38010, 304) \n"
     ]
    }
   ],
   "source": [
    "print 'X_train shape %s and X_test shape %s ' %(X_train.shape, X_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## model specification\n",
    "model = XGBClassifier(seed=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'n_estimators': [100, 250, 500],\n",
    "        'learning_rate': [0.05, 0.1, 0.3],\n",
    "        'max_depth': [3, 5],\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'colsample_bytree': [0.7, 0.8],\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(model, parameters, scoring='roc_auc', n_jobs=1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=4242, silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 250, 500], 'subsample': [0.8, 0.9], 'learning_rate': [0.05, 0.1, 0.3], 'colsample_bytree': [0.7, 0.8], 'max_depth': [3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839090694067\n",
      "colsample_bytree: 0.7\n",
      "learning_rate: 0.1\n",
      "max_depth: 3\n",
      "n_estimators: 100\n",
      "subsample: 0.8\n"
     ]
    }
   ],
   "source": [
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print score\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print \"%s: %r\" % (param_name, best_parameters[param_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.65,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=2, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=1234, silent=True, subsample=0.75)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train different models\n",
    "model1 = XGBClassifier(n_estimators=100, colsample_bytree=0.7, subsample=0.8, seed=4242, learning_rate=0.1, max_depth=3)\n",
    "model2 = XGBClassifier(n_estimators=100, colsample_bytree=0.65, subsample=0.75, min_child_weight=2, seed=1234, learning_rate=0.1, max_depth=2)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample prediction AUC score  0.835365548697\n",
      "Out of sample prediction AUC score  0.832326664678\n"
     ]
    }
   ],
   "source": [
    "predictions1 = model1.predict_proba(X_test)[:, 1]\n",
    "predictions2 = model2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print 'Out of sample prediction AUC score ', roc_auc_score(y_test, predictions1)\n",
    "print 'Out of sample prediction AUC score ', roc_auc_score(y_test, predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_for_ranked(preds, index):\n",
    "    ranks = []\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        ranks.append((index[i], pred))\n",
    "\n",
    "    return ranks\n",
    "\n",
    "def ranked_averaging(predictions):\n",
    "    all_ranks = defaultdict(list)\n",
    "\n",
    "    for i, preds in enumerate(predictions):\n",
    "        individual_ranks = []\n",
    "\n",
    "        for e, pred in enumerate(preds):\n",
    "            individual_ranks.append( (float(pred[1]), e, pred[0]) )\n",
    "\n",
    "        for rank, item in enumerate( sorted(individual_ranks) ) :\n",
    "            all_ranks[(item[1], item[2])].append(rank)\n",
    "\n",
    "    average_ranks = []\n",
    "\n",
    "    for k in sorted(all_ranks):\n",
    "        average_ranks.append((sum(all_ranks[k])/len(all_ranks[k]),k))\n",
    "\n",
    "    ranked_ranks = []\n",
    "\n",
    "    for rank, k in enumerate(sorted(average_ranks)):\n",
    "        ranked_ranks.append((k[1][0],k[1][1],(rank * 1.)/(len(average_ranks)-1)))\n",
    "    return sorted(ranked_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## average predictions of linear and gbm model to see how it performs\n",
    "\n",
    "transformed_gbm_predictions_1 = transform_for_ranked(predictions1, X_test.index.values)\n",
    "transformed_gbm_predictions_2 = transform_for_ranked(predictions2, X_test.index.values)\n",
    "\n",
    "prediction_ranks = ranked_averaging([transformed_gbm_predictions_1, transformed_gbm_predictions_2])\n",
    "ensemble_ranks = [k3 for k1, k2, k3 in prediction_ranks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score after ensembling ranks 0.834479 \n"
     ]
    }
   ],
   "source": [
    "print 'AUC score after ensembling ranks %f ' %(roc_auc_score(y_test, ensemble_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gbm</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.798724</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gbm        rf\n",
       "gbm  1.000000  0.798724\n",
       "rf   0.798724  1.000000"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'rf': rfPredictions, 'gbm': gbmPredictions}).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creates blending set for training and test and list of classifiers\n",
    "\n",
    "def get_blending_sets(X_train, y_train, X_test, n_folds=5,):\n",
    "    n_trees = 100\n",
    "    n_folds = n_folds\n",
    "\n",
    "    # Our level 0 classifiers\n",
    "    clfs = [\n",
    "        RandomForestClassifier(n_estimators = n_trees, criterion = 'gini', n_jobs=-1),\n",
    "        ExtraTreesClassifier(n_estimators = n_trees * 2, criterion = 'gini', n_jobs=-1),\n",
    "        RandomForestClassifier(n_estimators = n_trees, criterion = 'entropy', n_jobs=-1),\n",
    "        ExtraTreesClassifier(n_estimators = n_trees * 2, criterion = 'entropy', n_jobs=-1),\n",
    "        XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, colsample_bytree=0.7, subsample=0.8)\n",
    "    ]\n",
    "\n",
    "    # Ready for cross validation\n",
    "    skf = list(StratifiedKFold(y_train, n_folds))\n",
    "\n",
    "    # Pre-allocate the data\n",
    "    blend_train = np.zeros((X_train.shape[0], len(clfs))) # Number of training data x Number of classifiers\n",
    "    blend_test = np.zeros((X_test.shape[0], len(clfs))) # Number of testing data x Number of classifiers\n",
    "\n",
    "    print 'X_test.shape = %s' % (str(X_test.shape))\n",
    "    print 'blend_train.shape = %s' % (str(blend_train.shape))\n",
    "    print 'blend_test.shape = %s' % (str(blend_test.shape))\n",
    "    \n",
    "    return blend_train, blend_test, clfs, skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Takes in classifier, training set, labels, and test set\n",
    "## on which we predict stuff on\n",
    "\n",
    "def stacking(clfs, X_train, y_train, X_test, blend_train, blend_test, skf, y_test=None):\n",
    "    \n",
    "    # For each classifier, we train the number of fold times (=len(skf))\n",
    "    for j, clf in enumerate(clfs):\n",
    "        print 'Training classifier [%s]' % (j)\n",
    "        blend_test_j = np.zeros((X_test.shape[0], len(skf))) # Number of testing data x Number of folds , we will take the mean of the predictions later\n",
    "        for i, (train_index, cv_index) in enumerate(skf):\n",
    "            print 'Fold [%s]' % (i)\n",
    "\n",
    "            # This is the training and validation set\n",
    "            X_dev = X_train.iloc[train_index]\n",
    "            Y_dev = y_train.iloc[train_index]\n",
    "            X_cv = X_train.iloc[cv_index]\n",
    "            Y_cv = y_train.iloc[cv_index]\n",
    "\n",
    "            clf.fit(X_dev, Y_dev)\n",
    "\n",
    "            # This output will be the basis for our blended classifier to train against,\n",
    "            # which is also the output of our classifiers\n",
    "            blend_train[cv_index, j] = clf.predict_proba(X_cv)[:, 1]\n",
    "            blend_test_j[:, i] = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Take the mean of the predictions of the cross validation set\n",
    "        blend_test[:, j] = blend_test_j.mean(1)\n",
    "\n",
    "    print 'y_train.shape = %s' % (y_train.shape)\n",
    "\n",
    "    # Start blending!\n",
    "    bclf = LogisticRegression()\n",
    "    bclf.fit(blend_train, y_train)\n",
    "\n",
    "    # Predict now\n",
    "    Y_test_predict = bclf.predict_proba(blend_test)[:, 1]\n",
    "    \n",
    "    if y_test:\n",
    "        score = roc_auc_score(y_test, Y_test_predict)\n",
    "        print 'roc_auc_score = %s' % (score)\n",
    "    \n",
    "    return Y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape = (38010, 304)\n",
      "blend_train.shape = (38010, 5)\n",
      "blend_test.shape = (38010, 5)\n"
     ]
    }
   ],
   "source": [
    "blend_train, blend_test, clfs, skf = get_blending_sets(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [0]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [1]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [2]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [3]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [4]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "y_train.shape = 38010\n"
     ]
    }
   ],
   "source": [
    "predictionsStacking = stacking(clfs, X_train, y_train, X_test, blend_train, blend_test, skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC for stacking 0.836646 \n"
     ]
    }
   ],
   "source": [
    "print 'ROC AUC for stacking %f ' %(roc_auc_score(y_test, predictionsStacking))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape = (75818, 307)\n",
      "blend_train.shape = (76020, 5)\n",
      "blend_test.shape = (75818, 5)\n"
     ]
    }
   ],
   "source": [
    "blend_train, blend_test, clfs = get_blending_sets(X, y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [0]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [1]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [2]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [3]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [4]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "y_train.shape = 76020\n"
     ]
    }
   ],
   "source": [
    "predictions = stacking(clfs, X, y, test, blend_train, blend_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission['TARGET'] = predictions\n",
    "submission.to_csv('../submissions/stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
