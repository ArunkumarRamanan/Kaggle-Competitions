{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(1294)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col='ID')\n",
    "test = pd.read_csv('../data/test.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get features with zero standard deviation\n",
    "def get_constant_features(df):\n",
    "    columns = df.columns\n",
    "    return [col for col in columns if df[col].std() == 0.0]\n",
    "\n",
    "constant_features = get_constant_features(train)\n",
    "\n",
    "# get features which are identical to other features\n",
    "def get_identical_features(df):\n",
    "    columns = df.columns\n",
    "    identical_feat = []\n",
    "    \n",
    "    for i in range(len(columns)):\n",
    "        for j in range(i+1, len(columns)):\n",
    "            if (df[columns[i]] == df[columns[j]]).all():\n",
    "                identical_feat.append(columns[i])\n",
    "    \n",
    "    return identical_feat\n",
    "\n",
    "identical_feat = get_identical_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features_to_remove(constant_features, identical_features):\n",
    "    features_to_remove = []\n",
    "    \n",
    "    for feat in constant_features:\n",
    "        features_to_remove.append(feat)\n",
    "    \n",
    "    for feat in identical_features:\n",
    "        features_to_remove.append(feat)\n",
    "    \n",
    "    return features_to_remove\n",
    "\n",
    "remove_features = get_features_to_remove(constant_features, identical_feat)\n",
    "remove_features.append('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_features = train.columns.drop(remove_features)\n",
    "X = train[reduced_features]\n",
    "y = train.TARGET\n",
    "\n",
    "test = test[reduced_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0, learning_rate=0.05, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=2, missing=None, n_estimators=200, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=4242, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=200, colsample_bytree=0.7, learning_rate=0.05, max_depth=2, subsample=0.8, seed=4242, min_child_weight=2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample prediction AUC score  0.834566578097\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_proba(X_test)[:, 1]\n",
    "print 'Out of sample prediction AUC score ', roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_for_ranked(preds, index):\n",
    "    ranks = []\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        ranks.append((index[i], pred))\n",
    "\n",
    "    return ranks\n",
    "\n",
    "def ranked_averaging(predictions):\n",
    "    all_ranks = defaultdict(list)\n",
    "\n",
    "    for i, preds in enumerate(predictions):\n",
    "        individual_ranks = []\n",
    "\n",
    "        for e, pred in enumerate(preds):\n",
    "            individual_ranks.append( (float(pred[1]), e, pred[0]) )\n",
    "\n",
    "        for rank, item in enumerate( sorted(individual_ranks) ) :\n",
    "            all_ranks[(item[1], item[2])].append(rank)\n",
    "\n",
    "    average_ranks = []\n",
    "\n",
    "    for k in sorted(all_ranks):\n",
    "        average_ranks.append((sum(all_ranks[k])/len(all_ranks[k]),k))\n",
    "\n",
    "    ranked_ranks = []\n",
    "\n",
    "    for rank, k in enumerate(sorted(average_ranks)):\n",
    "        ranked_ranks.append((k[1][0],k[1][1],(rank * 1.)/(len(average_ranks)-1)))\n",
    "    return sorted(ranked_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## average predictions of linear and gbm model to see how it performs\n",
    "\n",
    "transformed_gbm_predictions = transform_for_ranked(gbmPredictions, X_test.index.values)\n",
    "prediction_ranks = ranked_averaging([transformed_rf_predictions, transformed_gbm_predictions])\n",
    "ensemble_ranks = [k3 for k1, k2, k3 in prediction_ranks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score after ensembling ranks 0.827524 \n"
     ]
    }
   ],
   "source": [
    "print 'AUC score after ensembling ranks %f ' %(roc_auc_score(y_test, ensemble_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gbm</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.798724</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gbm        rf\n",
       "gbm  1.000000  0.798724\n",
       "rf   0.798724  1.000000"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'rf': rfPredictions, 'gbm': gbmPredictions}).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creates blending set for training and test and list of classifiers\n",
    "\n",
    "def get_blending_sets(X_train, y_train, X_test, n_folds=5,):\n",
    "    n_trees = 100\n",
    "    n_folds = n_folds\n",
    "\n",
    "    # Our level 0 classifiers\n",
    "    clfs = [\n",
    "        RandomForestClassifier(n_estimators = n_trees, criterion = 'gini', n_jobs=-1),\n",
    "        ExtraTreesClassifier(n_estimators = n_trees * 2, criterion = 'gini', n_jobs=-1),\n",
    "        XGBClassifier(learning_rate=0.01, seed=1234, n_estimators=n_trees * 2, max_depth=6, min_child_weight=5, colsample_bytree=0.7, subsample=0.9),\n",
    "        XGBClassifier(learning_rate=0.1, seed=1234, n_estimators=n_trees, max_depth=3, min_child_weight=5, colsample_bytree=0.7, subsample=0.9),\n",
    "        XGBClassifier(learning_rate=0.02, seed=1234, n_estimators=n_trees, max_depth=3, min_child_weight=5, colsample_bytree=0.7, subsample=0.9)\n",
    "    ]\n",
    "\n",
    "    # Ready for cross validation\n",
    "    skf = list(StratifiedKFold(y_train, n_folds))\n",
    "\n",
    "    # Pre-allocate the data\n",
    "    blend_train = np.zeros((X_train.shape[0], len(clfs))) # Number of training data x Number of classifiers\n",
    "    blend_test = np.zeros((X_test.shape[0], len(clfs))) # Number of testing data x Number of classifiers\n",
    "\n",
    "    print 'X_test.shape = %s' % (str(X_test.shape))\n",
    "    print 'blend_train.shape = %s' % (str(blend_train.shape))\n",
    "    print 'blend_test.shape = %s' % (str(blend_test.shape))\n",
    "    \n",
    "    return blend_train, blend_test, clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Takes in classifier, training set, labels, and test set\n",
    "## on which we predict stuff on\n",
    "\n",
    "def stacking(clfs, X_train, y_train, X_test, blend_train, blend_test, y_test=None):\n",
    "    \n",
    "    # For each classifier, we train the number of fold times (=len(skf))\n",
    "    for j, clf in enumerate(clfs):\n",
    "        print 'Training classifier [%s]' % (j)\n",
    "        blend_test_j = np.zeros((X_test.shape[0], len(skf))) # Number of testing data x Number of folds , we will take the mean of the predictions later\n",
    "        for i, (train_index, cv_index) in enumerate(skf):\n",
    "            print 'Fold [%s]' % (i)\n",
    "\n",
    "            # This is the training and validation set\n",
    "            X_dev = X_train.iloc[train_index]\n",
    "            Y_dev = y_train.iloc[train_index]\n",
    "            X_cv = X_train.iloc[cv_index]\n",
    "            Y_cv = y_train.iloc[cv_index]\n",
    "\n",
    "            clf.fit(X_dev, Y_dev)\n",
    "\n",
    "            # This output will be the basis for our blended classifier to train against,\n",
    "            # which is also the output of our classifiers\n",
    "            blend_train[cv_index, j] = clf.predict_proba(X_cv)[:, 1]\n",
    "            blend_test_j[:, i] = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Take the mean of the predictions of the cross validation set\n",
    "        blend_test[:, j] = blend_test_j.mean(1)\n",
    "\n",
    "    print 'y_train.shape = %s' % (y_train.shape)\n",
    "\n",
    "    # Start blending!\n",
    "    bclf = LogisticRegression()\n",
    "    bclf.fit(blend_train, y_train)\n",
    "\n",
    "    # Predict now\n",
    "    Y_test_predict = bclf.predict_proba(blend_test)[:, 1]\n",
    "    \n",
    "    if y_test:\n",
    "        score = roc_auc_score(y_test, Y_test_predict)\n",
    "        print 'roc_auc_score = %s' % (score)\n",
    "    \n",
    "    return Y_test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape = (75818, 307)\n",
      "blend_train.shape = (76020, 5)\n",
      "blend_test.shape = (75818, 5)\n"
     ]
    }
   ],
   "source": [
    "blend_train, blend_test, clfs = get_blending_sets(X, y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [0]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [1]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [2]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [3]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "Training classifier [4]\n",
      "Fold [0]\n",
      "Fold [1]\n",
      "Fold [2]\n",
      "Fold [3]\n",
      "Fold [4]\n",
      "y_train.shape = 76020\n"
     ]
    }
   ],
   "source": [
    "predictions = stacking(clfs, X, y, test, blend_train, blend_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission['TARGET'] = predictions\n",
    "submission.to_csv('../submissions/stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
