{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load external scripts\n",
    "%run scripts/helper.py\n",
    "%run scripts/model_train_plus_test.py\n",
    "%run query_features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load training and test data downloaded from kaggle\n",
    "crowd_train = load_file('./data/train.csv/train.csv', None)\n",
    "crowd_test = load_file('./data/test.csv/test.csv', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the response variable\n",
    "target = crowd_train.median_relevance.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a stratified split of the dataset to get a sample\n",
    "# that would have same class frequency as the crowd_train dataset\n",
    "\n",
    "train_index, test_index = ssSplit(target, train_size=8000, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "training_data = crowd_train.iloc[train_index]\n",
    "testing_data = crowd_train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process data \n",
    "Xt = tweak_text(training_data)\n",
    "Xv = tweak_text(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yt = target[train_index]\n",
    "yv = target[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 fold Stacking\n",
    "\n",
    "* Split the train set in 2 parts: train_a and train_b\n",
    "* Fit a first-stage model on train_a and create predictions for train_b\n",
    "* Fit the same model on train_b and create predictions for train_a\n",
    "* Finally fit the model on the entire train set and create predictions for the test set.\n",
    "* Now train a second-stage stacker model on the probabilities from the first-stage model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of words model with ngram range = (1, 2)\n",
    "Xfitted, tfv = TFIDF(Xt, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_len = Xfitted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into two parts\n",
    "Xfitted_a  = Xfitted[:train_data_len/2]\n",
    "Xfitted_b = Xfitted[train_data_len/2:]\n",
    "\n",
    "ya = yt[:train_data_len/2]\n",
    "yb = yt[train_data_len/2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a linear model on train_a\n",
    "linear_model_a, select_a = build_linear_model(Xfitted_a, ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform train_b\n",
    "Xfitted_b_transformed = select_a.transform(Xfitted_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xfitted_b_preds = linear_model_a.predict_proba(Xfitted_b_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a linear model on train_b\n",
    "linear_model_b, select_b = build_linear_model(Xfitted_b, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform train_a\n",
    "Xfitted_a_transformed = select_b.transform(Xfitted_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions for train_a\n",
    "Xfitted_a_preds = linear_model_b.predict_proba(Xfitted_a_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_a = stack([Xfitted_a_preds, Xfitted_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_b = stack([Xfitted_b_preds, Xfitted_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_first_stage = concat_examples([features_a, features_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets train a linear model on this feature set\n",
    "linear_model, select = build_linear_model(features_first_stage, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate probabilities for the features\n",
    "features_first_stage_selected = select.transform(features_first_stage)\n",
    "first_stage_probabilities = linear_model.predict_proba(features_first_stage_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train second stage classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)\n",
    "\n",
    "scl = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "clf = SVC(C=10.0, kernel='rbf', degree=3, \n",
    "        gamma=0.0, coef0=0.0, shrinking=True, probability=False, \n",
    "        tol=0.001, cache_size=200, class_weight=None, \n",
    "        verbose=False, max_iter=-1, random_state=None)\n",
    "\n",
    "keywords = keyword_counter(training_data)\n",
    "# keywords = keyword_counter(crowd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stack previous stage predictions with features generated for\n",
    "# second stage model\n",
    "features_second_stage = stack([first_stage_probabilities, keywords, Xfitted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 40027)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the features dataframe\n",
    "features_second_stage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('svd', svd), ('scl', scl), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('svd', TruncatedSVD(algorithm='randomized', n_components=200, n_iter=5,\n",
       "       random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(features_second_stage, yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Prediction on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xv_fitted = tfv.transform(Xv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xv_data_len = len(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xv_fitted_a = Xv_fitted[:Xv_data_len/2]\n",
    "Xv_fitted_b = Xv_fitted[Xv_data_len/2:]\n",
    "\n",
    "yv_a = yv[:Xv_data_len/2]\n",
    "yv_b = yv[Xv_data_len/2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xv_fitted_b_transformed = select_a.transform(Xv_fitted_b)\n",
    "Xv_fitted_b_preds = linear_model_a.predict_proba(Xv_fitted_b_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xv_fitted_a_transformed = select_b.transform(Xv_fitted_a)\n",
    "Xv_fitted_a_preds = linear_model_b.predict_proba(Xv_fitted_a_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test_a = stack([Xv_fitted_a_preds, Xv_fitted_a])\n",
    "features_test_b = stack([Xv_fitted_b_preds, Xv_fitted_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test = concat_examples([features_test_a, features_test_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test_transformed = select.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_stage_test_preds = linear_model.predict_proba(features_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords_test = keyword_counter(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_second_stage_test = stack([first_stage_test_preds, keywords_test, Xv_fitted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_stage_preds = pipeline.predict(fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
