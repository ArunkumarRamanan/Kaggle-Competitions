{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run scripts/helper.py\n",
    "%run scripts/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crowd_train = load_file('./data/train.csv/train.csv', index_col='id')\n",
    "# crowd_test = load_file('./data/test.csv/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "# train_index, test_index = ssSplit(crowd_train.median_relevance, train_size=8000, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of training examples\n",
    "# print len(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of test examples\n",
    "# print len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare training and validation set\n",
    "\n",
    "# train = crowd_train.iloc[train_index]\n",
    "# train_target = crowd_train.median_relevance.iloc[train_index].values\n",
    "# validation = crowd_train.iloc[test_index]\n",
    "# validation_target = crowd_train.median_relevance.iloc[test_index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Prepare training on full training and test set\n",
    "\n",
    "train = crowd_train\n",
    "train_target = crowd_train.median_relevance.values\n",
    "# validation = crowd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = prepareText(train)\n",
    "#validation_text = prepareText(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF on  full dataset rather than only on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_plus_test = []\n",
    "\n",
    "# for i in range(len(train_text)):\n",
    "#     train_plus_test.append(train_text[i])\n",
    "\n",
    "# for i in range(len(validation_text)):\n",
    "#     train_plus_test.append(validation_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(train_plus_test), ' ', len(train_text), ' ', len(validation_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Linear Model using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(non_linear_model, tfv, svd, scl) = build_non_linear_model(train_text, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print weighted kappa score on the training and test set\n",
    "\n",
    "\n",
    "# training_preds_non = non_linear_model_predictions(non_linear_model, tfv, svd, scl, train_text)\n",
    "# validation_preds_non = non_linear_model_predictions(non_linear_model, tfv, svd, scl, validation_text)\n",
    "\n",
    "# print 'score on training set %0.4f ' %(quadratic_weighted_kappa(training_preds_non, train_target))\n",
    "# print '#############################'\n",
    "# print 'score on test set %0.4f ' %(quadratic_weighted_kappa(validation_preds_non, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kneighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (knn_model, tfv_knn, svd_knn) = build_knn_model(train_text, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training_preds_knn = knn_model_predictions(knn_model, tfv_knn, svd_knn, train_text)\n",
    "# validation_preds_knn = knn_model_predictions(knn_model, tfv_knn, svd_knn, validation_text)\n",
    "\n",
    "# print 'score on training set %0.4f ' %(quadratic_weighted_kappa(training_preds_knn, train_target))\n",
    "# print '#############################'\n",
    "# print 'score on test set %0.4f ' %(quadratic_weighted_kappa(validation_preds_knn, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (bayes_model, tfv_bayes) = build_naive_bayes(train_text, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training_preds_bayes = naive_bayes_predictions(bayes_model, tfv_bayes, train_text)\n",
    "# validation_preds_bayes = naive_bayes_predictions(bayes_model, tfv_bayes, validation_text)\n",
    "\n",
    "# print 'score on training set %0.4f ' %(quadratic_weighted_kappa(training_preds_bayes, train_target))\n",
    "# print '#############################'\n",
    "# print 'score on test set %0.4f ' %(quadratic_weighted_kappa(validation_preds_bayes, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different model which tweaks stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tweaked_text = tweak_text(train)\n",
    "# validation_tweaked_text = tweak_text(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_plus_test_tweak = []\n",
    "\n",
    "# for i in range(len(train_tweaked_text)):\n",
    "#     train_plus_test_tweak.append(train_tweaked_text[i])\n",
    "\n",
    "# for i in range(len(validation_tweaked_text)):\n",
    "#     train_plus_test_tweak.append(validation_tweaked_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(tweaked_model, tfv_tweaked, svd_tweaked, scl_tweaked) = build_stopwords_tweak_model(train_tweaked_text, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training_preds_tweak = non_linear_model_predictions(tweaked_model, tfv_tweaked, svd_tweaked, scl_tweaked, train_tweaked_text)\n",
    "# validation_preds_tweak = non_linear_model_predictions(tweaked_model, tfv_tweaked, svd_tweaked, scl_tweaked, validation_tweaked_text)\n",
    "\n",
    "# print 'score on training set %0.4f ' %(quadratic_weighted_kappa(training_preds_tweak, train_target))\n",
    "# print '#############################'\n",
    "# print 'score on test set %0.4f ' %(quadratic_weighted_kappa(validation_preds_tweak, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read big test set csv file in chunks of 5000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "test_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for test in pd.read_csv('./data/test.csv/test.csv', index_col='id', chunksize=5000):\n",
    "    test = test.fillna('')\n",
    "    \n",
    "    test_text = prepareText(test)\n",
    "    test_preds_non = non_linear_model_predictions(non_linear_model, tfv, svd, scl, test_text)\n",
    "\n",
    "    test_tweaked_text = tweak_text(test)\n",
    "    test_preds_tweaked = non_linear_model_predictions(tweaked_model, tfv_tweaked, svd_tweaked, scl_tweaked, test_tweaked_text)\n",
    "\n",
    "    test_predictions.append((test_preds_non + test_preds_tweaked) / 2)\n",
    "    test_ids.append(test.index.values.astype(int))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.hstack(test_predictions)\n",
    "ids = np.hstack(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see how the ensemble of these different techniques work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pred_train = (training_preds_tweak + training_preds_non ) / 2\n",
    "# pred_test = (validation_preds_tweak + validation_preds_non ) / 2\n",
    "\n",
    "# print 'score on training set %0.4f ' %(quadratic_weighted_kappa(pred_train, train_target))\n",
    "# print '#############################'\n",
    "# print 'score on test set %0.4f ' %(quadratic_weighted_kappa(pred_test, validation_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_submission(ids, preds, 'ensemble_high_hopes_fingers_crossed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
