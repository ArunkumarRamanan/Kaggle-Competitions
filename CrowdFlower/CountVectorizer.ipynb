{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run scripts/helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crowd_train = load_file('./data/train.csv/train.csv', index_col='id')\n",
    "crowd_test = load_file('./data/test.csv/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindata = prepareText(crowd_train)\n",
    "testdata = prepareText(crowd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = getTargetVariable(crowd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=3,  max_features=None, \n",
    "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit count vectorizer on train and test data\n",
    "X = cv.fit_transform(traindata)\n",
    "X_test = cv.transform(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Weighted kappa scorer\n",
    "kappa_scorer = make_scorer(quadratic_weighted_kappa, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt, Xv, yt, yv = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8126, 44460) (2032, 44460) (8126,) (2032,)\n"
     ]
    }
   ],
   "source": [
    "print Xt.shape, Xv.shape, yt.shape, yv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=140)\n",
    "Xt = svd.fit_transform(Xt)\n",
    "Xv = svd.transform(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "Xt = scl.fit_transform(Xt)\n",
    "Xv = scl.transform(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
       "  gamma=0.01, kernel='rbf', max_iter=-1, probability=False,\n",
       "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=10.0, gamma=0.01)\n",
    "svc.fit(Xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on training set 0.670 \n"
     ]
    }
   ],
   "source": [
    "print 'score on training set %0.3f ' %(quadratic_weighted_kappa(yt, svc.predict(Xt))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test set 0.257 \n"
     ]
    }
   ],
   "source": [
    "print 'score on test set %0.3f ' %(quadratic_weighted_kappa(yv, svc.predict(Xv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  31,   20,    9,  105],\n",
       "       [  13,   44,   26,  191],\n",
       "       [  11,   36,   51,  278],\n",
       "       [  18,   41,   56, 1102]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yv, svc.predict(Xv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix suggests that most of the values are mistaken for 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train two separate models and ensemble them if they are found un-correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_relevance_variation = crowd_train.relevance_variance.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_1 = crowd_train[crowd_train.relevance_variance < mean_relevance_variation]\n",
    "train_response_1 = crowd_train[crowd_train.relevance_variance < mean_relevance_variation]['median_relevance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_2 = crowd_train[crowd_train.relevance_variance >= mean_relevance_variation]\n",
    "train_response_2 = crowd_train[crowd_train.relevance_variance >= mean_relevance_variation]['median_relevance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4439, 5) (4439,) (5719, 5) (5719,)\n"
     ]
    }
   ],
   "source": [
    "print train_data_1.shape, train_response_1.shape, train_data_2.shape, train_response_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_text_1 = prepareText(train_data_1)\n",
    "train_data_text_2 = prepareText(train_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4439 5719\n"
     ]
    }
   ],
   "source": [
    "print len(train_data_text_1), len(train_data_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_train_1 = train_data_text_1[:3000]\n",
    "y_train_1 = train_response_1[:3000]\n",
    "train_data_test_1 = train_data_text_1[3000:]\n",
    "y_test_1 = train_response_1[3000:]\n",
    "\n",
    "train_data_train_2 = train_data_text_2[:4000]\n",
    "y_train_2 = train_response_2[:4000]\n",
    "train_data_test_2 = train_data_text_2[4000:]\n",
    "y_test_2 = train_response_2[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "        stop_words = 'english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt_1 = tfv.fit_transform(train_data_train_1)\n",
    "Xv_1 = tfv.transform(train_data_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt_2 = tfv.fit_transform(train_data_train_2)\n",
    "Xv_2 = tfv.transform(train_data_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd1 = TruncatedSVD(n_components=140)\n",
    "\n",
    "Xt_1 = svd1.fit_transform(Xt_1)\n",
    "Xv_1 = svd1.transform(Xv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd2 = TruncatedSVD(n_components=140)\n",
    "\n",
    "Xt_2 = svd2.fit_transform(Xt_2)\n",
    "Xv_2 = svd2.transform(Xv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "\n",
    "Xt_1 = scl.fit_transform(Xt_1)\n",
    "Xv_1 = scl.transform(Xv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "\n",
    "Xt_2 = scl.fit_transform(Xt_2)\n",
    "Xv_2 = scl.transform(Xv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
       "  gamma=0.01, kernel='rbf', max_iter=-1, probability=False,\n",
       "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc1 = SVC(C=10.0, gamma=.01)\n",
    "svc1.fit(Xt_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=6.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.01,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc2 = SVC(C=6.0, gamma=0.01)\n",
    "svc2.fit(Xt_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score on first dataset 0.9656 \n"
     ]
    }
   ],
   "source": [
    "print 'training score on first dataset %0.4f ' %(quadratic_weighted_kappa(y_train_1, svc1.predict(Xt_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score on second dataset 0.8687 \n"
     ]
    }
   ],
   "source": [
    "print 'training score on second dataset %0.4f ' %(quadratic_weighted_kappa(y_train_2, svc2.predict(Xt_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score on first dataset 0.5940 \n"
     ]
    }
   ],
   "source": [
    "print 'test score on first dataset %0.4f ' %(quadratic_weighted_kappa(y_test_1, svc1.predict(Xv_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score on second dataset 0.3243 \n"
     ]
    }
   ],
   "source": [
    "print 'test score on second dataset %0.4f ' %(quadratic_weighted_kappa(y_test_2, svc2.predict(Xv_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble prediction on first dataset 0.4050 \n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_1 = (svc1.predict(Xv_1) + svc2.predict(Xv_1)) / 2\n",
    "print 'ensemble prediction on first dataset %0.4f ' %(quadratic_weighted_kappa(y_test_1, ensemble_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble prediction on second dataset 0.2573 \n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_2 = (svc1.predict(Xv_2) + svc2.predict(Xv_2)) / 2\n",
    "print 'ensemble prediction on second dataset %0.4f ' %(quadratic_weighted_kappa(y_test_2, ensemble_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
