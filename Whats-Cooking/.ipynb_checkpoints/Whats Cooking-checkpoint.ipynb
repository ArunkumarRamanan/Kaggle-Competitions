{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import external libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_json(filename='./data/train.json'):\n",
    "    \"\"\"\n",
    "    Reads in a file and returns json \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename) as infile:\n",
    "        return json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_column_names(row):\n",
    "    \"\"\"\n",
    "    Takes in a row of the data and returns column names\n",
    "    \"\"\"\n",
    "    return row.keys()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content(row, col_name):\n",
    "    \"\"\"\n",
    "    Takes in a row and a column name\n",
    "    and returns a list of values\n",
    "    \"\"\"\n",
    "    if col_name == 'ingredients':\n",
    "        return ' '.join(row[col_name])\n",
    "    else:\n",
    "        return row[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whats_cooking_train = convert_to_json()\n",
    "whats_cooking_test = convert_to_json('./data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(json_repr):\n",
    "    \"\"\"\n",
    "    Takes in a json representation of the data\n",
    "    and returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    column_names = sorted(get_column_names(json_repr[0]))\n",
    "    cols = []\n",
    "    \n",
    "    for col_name in column_names:\n",
    "        cols.append([get_content(row, col_name) for row in json_repr])\n",
    "    \n",
    "    data = dict(zip(column_names, cols))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('id', inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whats_cooking_train_df = prepare_dataset(whats_cooking_train)\n",
    "whats_cooking_test_df = prepare_dataset(whats_cooking_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>greek</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25693</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20130</th>\n",
       "      <td>filipino</td>\n",
       "      <td>eggs pepper salt mayonaise cooking oil green c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22213</th>\n",
       "      <td>indian</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13162</th>\n",
       "      <td>indian</td>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cuisine                                        ingredients\n",
       "id                                                                   \n",
       "10259        greek  romaine lettuce black olives grape tomatoes ga...\n",
       "25693  southern_us  plain flour ground pepper salt tomatoes ground...\n",
       "20130     filipino  eggs pepper salt mayonaise cooking oil green c...\n",
       "22213       indian                     water vegetable oil wheat salt\n",
       "13162       indian  black pepper shallots cornflour cayenne pepper..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whats_cooking_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18009</th>\n",
       "      <td>baking powder eggs all-purpose flour raisins m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28583</th>\n",
       "      <td>sugar egg yolks corn starch cream of tartar ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41580</th>\n",
       "      <td>sausage links fennel bulb fronds olive oil cub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29752</th>\n",
       "      <td>meat cuts file powder smoked sausage okra shri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35687</th>\n",
       "      <td>ground black pepper salt sausage casings leeks...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ingredients\n",
       "id                                                      \n",
       "18009  baking powder eggs all-purpose flour raisins m...\n",
       "28583  sugar egg yolks corn starch cream of tartar ba...\n",
       "41580  sausage links fennel bulb fronds olive oil cub...\n",
       "29752  meat cuts file powder smoked sausage okra shri...\n",
       "35687  ground black pepper salt sausage casings leeks..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whats_cooking_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## What are the different unique ingredients used across various cuisines ?\n",
    "\n",
    "def get_ingredients(cuisines):\n",
    "    all_ingredients = []\n",
    "\n",
    "    for i in range(cuisines.shape[0]):\n",
    "        ## get all the ingredients\n",
    "        ingredients = cuisines.iloc[i, 1].split(' ') # 1 here marks first column for ingredients\n",
    "    \n",
    "        for ingredient in ingredients:\n",
    "            ingredient = re.sub(r'[^A-Za-z]', '', ingredient)\n",
    "            # omit empty space and stopwords as ingredient name\n",
    "            if len(ingredient) > 2:\n",
    "                all_ingredients.append(ingredient.lower())\n",
    "    \n",
    "    return all_ingredients\n",
    "\n",
    "def get_unique_ingredients(cuisines):\n",
    "    all_ingredients = get_ingredients(cuisines)\n",
    "    \n",
    "    return set(all_ingredients)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3030\n"
     ]
    }
   ],
   "source": [
    "print len(get_unique_ingredients(whats_cooking_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** There are 3030 different ingredients used across various cuisines, bearing in mind that we considered \n",
    "   e.g. black olives to be ['black', 'olive'] as two separate ingredients **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## What are the top most used ingredients ?\n",
    "\n",
    "def get_top_most_used_ingredients(cuisines):\n",
    "    all_ingredients = get_ingredients(cuisines)\n",
    "    \n",
    "    ## counts frequency of each ingredient\n",
    "    top_most_used_ingredients = Counter(all_ingredients)\n",
    "    \n",
    "    return sorted(top_most_used_ingredients, key=lambda x: top_most_used_ingredients[x], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_most_used_ingredients = get_top_most_used_ingredients(whats_cooking_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'pepper', u'salt', u'oil', u'garlic', u'ground', u'fresh', u'sauce', u'sugar', u'onions', u'cheese']\n"
     ]
    }
   ],
   "source": [
    "## 10 top most used ingredients\n",
    "print top_most_used_ingredients[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** This seems legit, indeed these are some of the top-most used ingredients in preparation of any cuisine **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Ingredients per cuisine\n",
    "\n",
    "def get_ingredients_per_cuisine(grouped_cuisines, names_of_cuisines):\n",
    "    ingredients_per_cuisine = {}\n",
    "    \n",
    "    for name in names_of_cuisines:\n",
    "        cuisine_group = grouped_cuisines.get_group(name)\n",
    "        ingredients_per_cuisine[name] = list(get_unique_ingredients(cuisine_group))\n",
    "    \n",
    "    return ingredients_per_cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_cuisines = whats_cooking_train_df.groupby(['cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_of_cuisines = whats_cooking_train_df.cuisine.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredients_per_cuisine = get_ingredients_per_cuisine(grouped_cuisines, names_of_cuisines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'irish', u'mexican', u'chinese', u'filipino', u'vietnamese', u'moroccan', u'brazilian', u'japanese', u'british', u'greek', u'indian', u'jamaican', u'french', u'spanish', u'russian', u'cajun_creole', u'thai', u'southern_us', u'korean', u'italian']\n"
     ]
    }
   ],
   "source": [
    "print ingredients_per_cuisine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'freerange', u'monterey', u'all', u'portabello', u'chinese', u'mackerel', u'yellow', u'soften', u'olive', u'mild', u'fivespice', u'skim', u'shortgrain', u'gluten', u'skin', u'roots', u'mascarpone', u'milk', u'cummin', u'preserves', u'grape', u'sago', u'pattypan', u'assam', u'peanut', u'sparkling', u'granular', u'curds', u'dressing', u'couscous', u'tzatziki', u'brown', u'turnips', u'demerara', u'quorn', u'garden', u'yeast', u'citrus', u'kewra', u'vegan', u'baton', u'vadouvan', u'jalape', u'figs', u'softened', u'mooli', u'kappa', u'bhindi', u'minute', u'tortillas']\n"
     ]
    }
   ],
   "source": [
    "## Lets check out what ingredients define indian cuisines\n",
    "print ingredients_per_cuisine['indian'][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuisines_train = whats_cooking_train_df.copy()\n",
    "cuisines_test = whats_cooking_test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_ingredient_name(ingredient_name):\n",
    "    ingredient_name = re.sub(r'^A-Za-z', '', ingredient_name.lower())\n",
    "    return ingredient_name\n",
    "\n",
    "cuisines_train['ingredients'] = cuisines_train.ingredients.map(process_ingredient_name)\n",
    "cuisines_test['ingredients'] = cuisines_test.ingredients.map(process_ingredient_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## training labels\n",
    "train_labels = cuisines_train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = lbl_encoder.transform(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## online learning algorithm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(target, test_size=0.3)\n",
    "\n",
    "train_index, test_index = next(iter(sss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = cuisines_train.iloc[train_index, 1]\n",
    "train_target = target[train_index]\n",
    "\n",
    "test_X = cuisines_train.iloc[test_index, 1]\n",
    "test_target = target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), stop_words=english_stopwords)\n",
    "X_train = vec.fit_transform(train_X)\n",
    "y_train = train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=0.5, fit_intercept=True, loss='hinge', n_iter=5,\n",
       "              n_jobs=1, random_state=None, shuffle=True, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac = PassiveAggressiveClassifier(C=0.5)\n",
    "pac.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score %f  0.988289388606\n"
     ]
    }
   ],
   "source": [
    "print 'Training score %f ', pac.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = vec.transform(test_X)\n",
    "y_test = test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score %f  0.780328418231\n"
     ]
    }
   ],
   "source": [
    "print 'Test score %f ', pac.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_bag_of_ingredients(cuisines):\n",
    "    one_hot_encoded = defaultdict(list)\n",
    "\n",
    "    for i in range(cuisines.shape[0]):\n",
    "        ingredient = cuisines.iloc[i, 1]\n",
    "        ingredient = re.sub(r'^A-Za-z', '', ingredient)\n",
    "        ingredient = ingredient.lower()\n",
    "\n",
    "        for u_ingr in top_most_used_ingredients[:500]:\n",
    "            if u_ingr in ingredient:\n",
    "                one_hot_encoded[u_ingr].append(1)\n",
    "            else:\n",
    "                one_hot_encoded[u_ingr].append(0)\n",
    "    \n",
    "    return one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_of_ingredients = prepare_bag_of_ingredients(cuisines_train.head(15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_of_ingredients_df = pd.DataFrame(bag_of_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15000 entries, 0 to 14999\n",
      "Columns: 500 entries, active to zucchini\n",
      "dtypes: int64(500)\n",
      "memory usage: 57.3 MB\n"
     ]
    }
   ],
   "source": [
    "bag_of_ingredients_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_ingredients_sparse = sparse.csr_matrix(bag_of_ingredients_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_target, test_target = train_test_split(bag_of_ingredients_sparse, target[:15000], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix( train_X, label=train_target )\n",
    "xg_test = xgb.DMatrix( test_X, label=test_target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.07\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 20\n",
    "param['colsample_bytree'] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.383583\ttest-merror:0.418667\n",
      "[1]\ttrain-merror:0.345167\ttest-merror:0.394000\n",
      "[2]\ttrain-merror:0.315333\ttest-merror:0.364333\n",
      "[3]\ttrain-merror:0.308833\ttest-merror:0.359000\n",
      "[4]\ttrain-merror:0.299167\ttest-merror:0.353333\n",
      "[5]\ttrain-merror:0.293167\ttest-merror:0.347333\n",
      "[6]\ttrain-merror:0.290000\ttest-merror:0.351000\n",
      "[7]\ttrain-merror:0.283917\ttest-merror:0.346333\n",
      "[8]\ttrain-merror:0.279917\ttest-merror:0.340333\n",
      "[9]\ttrain-merror:0.274750\ttest-merror:0.334667\n",
      "[10]\ttrain-merror:0.271583\ttest-merror:0.333000\n",
      "[11]\ttrain-merror:0.267667\ttest-merror:0.331333\n",
      "[12]\ttrain-merror:0.266667\ttest-merror:0.328333\n",
      "[13]\ttrain-merror:0.264167\ttest-merror:0.328333\n",
      "[14]\ttrain-merror:0.261500\ttest-merror:0.328667\n",
      "[15]\ttrain-merror:0.259000\ttest-merror:0.325667\n",
      "[16]\ttrain-merror:0.256500\ttest-merror:0.324667\n",
      "[17]\ttrain-merror:0.253833\ttest-merror:0.321667\n",
      "[18]\ttrain-merror:0.253083\ttest-merror:0.323000\n",
      "[19]\ttrain-merror:0.252500\ttest-merror:0.322333\n",
      "[20]\ttrain-merror:0.250583\ttest-merror:0.319333\n",
      "[21]\ttrain-merror:0.249083\ttest-merror:0.320000\n",
      "[22]\ttrain-merror:0.248333\ttest-merror:0.318667\n",
      "[23]\ttrain-merror:0.246083\ttest-merror:0.317000\n",
      "[24]\ttrain-merror:0.244667\ttest-merror:0.317000\n",
      "[25]\ttrain-merror:0.243000\ttest-merror:0.316333\n",
      "[26]\ttrain-merror:0.241833\ttest-merror:0.317333\n",
      "[27]\ttrain-merror:0.239750\ttest-merror:0.315667\n",
      "[28]\ttrain-merror:0.238750\ttest-merror:0.314333\n",
      "[29]\ttrain-merror:0.237083\ttest-merror:0.315667\n",
      "[30]\ttrain-merror:0.235500\ttest-merror:0.313667\n",
      "[31]\ttrain-merror:0.234917\ttest-merror:0.313667\n",
      "[32]\ttrain-merror:0.234000\ttest-merror:0.313333\n",
      "[33]\ttrain-merror:0.233167\ttest-merror:0.312000\n",
      "[34]\ttrain-merror:0.231583\ttest-merror:0.310667\n",
      "[35]\ttrain-merror:0.230167\ttest-merror:0.310000\n",
      "[36]\ttrain-merror:0.227917\ttest-merror:0.309333\n",
      "[37]\ttrain-merror:0.226417\ttest-merror:0.310333\n",
      "[38]\ttrain-merror:0.225500\ttest-merror:0.308667\n",
      "[39]\ttrain-merror:0.224333\ttest-merror:0.308333\n",
      "[40]\ttrain-merror:0.223500\ttest-merror:0.309667\n",
      "[41]\ttrain-merror:0.221417\ttest-merror:0.307000\n",
      "[42]\ttrain-merror:0.219417\ttest-merror:0.303333\n",
      "[43]\ttrain-merror:0.218667\ttest-merror:0.302000\n",
      "[44]\ttrain-merror:0.216250\ttest-merror:0.301667\n",
      "[45]\ttrain-merror:0.215333\ttest-merror:0.301667\n",
      "[46]\ttrain-merror:0.214750\ttest-merror:0.298333\n",
      "[47]\ttrain-merror:0.213250\ttest-merror:0.298333\n",
      "[48]\ttrain-merror:0.212000\ttest-merror:0.299000\n",
      "[49]\ttrain-merror:0.210750\ttest-merror:0.297000\n",
      "[50]\ttrain-merror:0.209583\ttest-merror:0.296333\n",
      "[51]\ttrain-merror:0.208000\ttest-merror:0.295667\n",
      "[52]\ttrain-merror:0.206000\ttest-merror:0.295667\n",
      "[53]\ttrain-merror:0.205417\ttest-merror:0.295333\n",
      "[54]\ttrain-merror:0.203250\ttest-merror:0.295333\n",
      "[55]\ttrain-merror:0.202583\ttest-merror:0.294000\n",
      "[56]\ttrain-merror:0.201583\ttest-merror:0.294000\n",
      "[57]\ttrain-merror:0.199500\ttest-merror:0.293333\n",
      "[58]\ttrain-merror:0.198500\ttest-merror:0.293000\n",
      "[59]\ttrain-merror:0.197000\ttest-merror:0.292000\n",
      "[60]\ttrain-merror:0.196667\ttest-merror:0.291000\n",
      "[61]\ttrain-merror:0.194333\ttest-merror:0.290333\n",
      "[62]\ttrain-merror:0.192583\ttest-merror:0.289000\n",
      "[63]\ttrain-merror:0.192667\ttest-merror:0.288000\n",
      "[64]\ttrain-merror:0.190917\ttest-merror:0.289333\n",
      "[65]\ttrain-merror:0.190167\ttest-merror:0.289667\n",
      "[66]\ttrain-merror:0.189083\ttest-merror:0.288667\n",
      "[67]\ttrain-merror:0.187333\ttest-merror:0.288333\n",
      "[68]\ttrain-merror:0.186417\ttest-merror:0.287667\n",
      "[69]\ttrain-merror:0.185500\ttest-merror:0.286667\n",
      "[70]\ttrain-merror:0.184250\ttest-merror:0.286667\n",
      "[71]\ttrain-merror:0.183667\ttest-merror:0.286333\n",
      "[72]\ttrain-merror:0.182750\ttest-merror:0.286667\n",
      "[73]\ttrain-merror:0.181333\ttest-merror:0.286333\n",
      "[74]\ttrain-merror:0.180750\ttest-merror:0.285667\n",
      "[75]\ttrain-merror:0.180000\ttest-merror:0.285333\n",
      "[76]\ttrain-merror:0.178917\ttest-merror:0.285000\n",
      "[77]\ttrain-merror:0.177667\ttest-merror:0.284667\n",
      "[78]\ttrain-merror:0.176667\ttest-merror:0.284333\n",
      "[79]\ttrain-merror:0.175250\ttest-merror:0.284000\n",
      "[80]\ttrain-merror:0.174333\ttest-merror:0.284333\n",
      "[81]\ttrain-merror:0.173500\ttest-merror:0.283667\n",
      "[82]\ttrain-merror:0.172667\ttest-merror:0.282333\n",
      "[83]\ttrain-merror:0.171833\ttest-merror:0.282667\n",
      "[84]\ttrain-merror:0.170583\ttest-merror:0.280667\n",
      "[85]\ttrain-merror:0.169917\ttest-merror:0.281000\n",
      "[86]\ttrain-merror:0.169417\ttest-merror:0.280000\n",
      "[87]\ttrain-merror:0.168750\ttest-merror:0.279667\n",
      "[88]\ttrain-merror:0.167500\ttest-merror:0.278667\n",
      "[89]\ttrain-merror:0.166583\ttest-merror:0.279333\n",
      "[90]\ttrain-merror:0.166083\ttest-merror:0.279000\n",
      "[91]\ttrain-merror:0.165167\ttest-merror:0.278333\n",
      "[92]\ttrain-merror:0.163917\ttest-merror:0.278667\n",
      "[93]\ttrain-merror:0.162833\ttest-merror:0.278000\n",
      "[94]\ttrain-merror:0.162000\ttest-merror:0.277000\n",
      "[95]\ttrain-merror:0.161083\ttest-merror:0.276333\n",
      "[96]\ttrain-merror:0.160000\ttest-merror:0.277000\n",
      "[97]\ttrain-merror:0.159333\ttest-merror:0.276667\n",
      "[98]\ttrain-merror:0.159000\ttest-merror:0.275333\n",
      "[99]\ttrain-merror:0.158500\ttest-merror:0.275333\n",
      "[100]\ttrain-merror:0.157833\ttest-merror:0.275000\n",
      "[101]\ttrain-merror:0.157000\ttest-merror:0.275333\n",
      "[102]\ttrain-merror:0.156500\ttest-merror:0.273667\n",
      "[103]\ttrain-merror:0.155750\ttest-merror:0.274000\n",
      "[104]\ttrain-merror:0.155000\ttest-merror:0.273333\n",
      "[105]\ttrain-merror:0.154833\ttest-merror:0.273667\n",
      "[106]\ttrain-merror:0.154167\ttest-merror:0.274000\n",
      "[107]\ttrain-merror:0.153417\ttest-merror:0.273000\n",
      "[108]\ttrain-merror:0.152250\ttest-merror:0.272333\n",
      "[109]\ttrain-merror:0.152250\ttest-merror:0.271667\n",
      "[110]\ttrain-merror:0.151250\ttest-merror:0.272333\n",
      "[111]\ttrain-merror:0.151083\ttest-merror:0.272333\n",
      "[112]\ttrain-merror:0.149833\ttest-merror:0.271000\n",
      "[113]\ttrain-merror:0.149250\ttest-merror:0.270333\n",
      "[114]\ttrain-merror:0.148917\ttest-merror:0.270000\n",
      "[115]\ttrain-merror:0.148167\ttest-merror:0.269333\n",
      "[116]\ttrain-merror:0.146417\ttest-merror:0.268667\n",
      "[117]\ttrain-merror:0.145667\ttest-merror:0.269667\n",
      "[118]\ttrain-merror:0.145000\ttest-merror:0.268667\n",
      "[119]\ttrain-merror:0.144000\ttest-merror:0.267333\n",
      "[120]\ttrain-merror:0.143750\ttest-merror:0.267667\n",
      "[121]\ttrain-merror:0.143417\ttest-merror:0.267333\n",
      "[122]\ttrain-merror:0.142500\ttest-merror:0.266667\n",
      "[123]\ttrain-merror:0.142250\ttest-merror:0.267000\n",
      "[124]\ttrain-merror:0.141500\ttest-merror:0.266667\n",
      "[125]\ttrain-merror:0.140750\ttest-merror:0.267000\n",
      "[126]\ttrain-merror:0.140000\ttest-merror:0.266667\n",
      "[127]\ttrain-merror:0.139583\ttest-merror:0.266000\n",
      "[128]\ttrain-merror:0.138667\ttest-merror:0.266333\n",
      "[129]\ttrain-merror:0.138417\ttest-merror:0.266333\n",
      "[130]\ttrain-merror:0.137750\ttest-merror:0.266000\n",
      "[131]\ttrain-merror:0.137333\ttest-merror:0.266000\n",
      "[132]\ttrain-merror:0.136250\ttest-merror:0.265333\n",
      "[133]\ttrain-merror:0.136083\ttest-merror:0.264667\n",
      "[134]\ttrain-merror:0.135750\ttest-merror:0.265333\n",
      "[135]\ttrain-merror:0.135583\ttest-merror:0.265000\n",
      "[136]\ttrain-merror:0.134750\ttest-merror:0.266000\n",
      "[137]\ttrain-merror:0.134083\ttest-merror:0.264333\n",
      "[138]\ttrain-merror:0.133500\ttest-merror:0.265333\n",
      "[139]\ttrain-merror:0.133167\ttest-merror:0.265000\n",
      "[140]\ttrain-merror:0.132667\ttest-merror:0.264333\n",
      "[141]\ttrain-merror:0.132250\ttest-merror:0.264333\n",
      "[142]\ttrain-merror:0.131917\ttest-merror:0.264667\n",
      "[143]\ttrain-merror:0.131250\ttest-merror:0.265000\n",
      "[144]\ttrain-merror:0.130833\ttest-merror:0.264000\n",
      "[145]\ttrain-merror:0.130250\ttest-merror:0.263667\n",
      "[146]\ttrain-merror:0.130333\ttest-merror:0.263667\n",
      "[147]\ttrain-merror:0.129667\ttest-merror:0.263000\n",
      "[148]\ttrain-merror:0.129417\ttest-merror:0.262667\n",
      "[149]\ttrain-merror:0.129250\ttest-merror:0.261667\n"
     ]
    }
   ],
   "source": [
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 150\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X_feat = vec.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=0.2, fit_intercept=True, loss='hinge', n_iter=5,\n",
       "              n_jobs=1, random_state=None, shuffle=True, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.fit(train_X_feat, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = vec.transform(cuisines_test.ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = pac.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_labels = lbl_encoder.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = cuisines_test.index.values\n",
    "submission_df = pd.DataFrame({'id': test_ids, 'cuisine': preds_labels})\n",
    "submission_df.to_csv('./submissions/stratified_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
